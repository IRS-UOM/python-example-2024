{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Helper Code"
      ],
      "metadata": {
        "id": "1jFeE1kfqyR2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wfdb"
      ],
      "metadata": {
        "id": "PULtpvXFrDxq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DY0pd0aLqw3y"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/env python\n",
        "\n",
        "# Do *not* edit this script.\n",
        "# These are helper functions that you can use with your code.\n",
        "# Check the example code to see how to use these functions in your code.\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "import wfdb\n",
        "\n",
        "### Challenge variables\n",
        "substring_labels = '# Labels:'\n",
        "substring_images = '# Image:'\n",
        "\n",
        "### Challenge data I/O functions\n",
        "\n",
        "# Find the records in a folder and its subfolders.\n",
        "def find_records(folder):\n",
        "    records = set()\n",
        "    for root, directories, files in os.walk(folder):\n",
        "        for file in files:\n",
        "            extension = os.path.splitext(file)[1]\n",
        "            if extension == '.hea':\n",
        "                record = os.path.relpath(os.path.join(root, file), folder)[:-4]\n",
        "                records.add(record)\n",
        "    records = sorted(records)\n",
        "    return records\n",
        "\n",
        "# Load the header for a record.\n",
        "def load_header(record):\n",
        "    header_file = get_header_file(record)\n",
        "    header = load_text(header_file)\n",
        "    return header\n",
        "\n",
        "# Load the signals for a record.\n",
        "def load_signals(record):\n",
        "    signal_files = get_signal_files(record)\n",
        "    path = os.path.split(record)[0]\n",
        "    signal_files_exist = all(os.path.isfile(os.path.join(path, signal_file)) for signal_file in signal_files)\n",
        "    if signal_files and signal_files_exist:\n",
        "        signal, fields = wfdb.rdsamp(record)\n",
        "    else:\n",
        "        signal, fields = None, None\n",
        "    return signal, fields\n",
        "\n",
        "# Load the images for a record.\n",
        "def load_images(record):\n",
        "    from PIL import Image\n",
        "\n",
        "    path = os.path.split(record)[0]\n",
        "    image_files = get_image_files(record)\n",
        "\n",
        "    images = list()\n",
        "    for image_file in image_files:\n",
        "        image_file_path = os.path.join(path, image_file)\n",
        "        if os.path.isfile(image_file_path):\n",
        "            image = Image.open(image_file_path)\n",
        "            images.append(image)\n",
        "\n",
        "    return images\n",
        "\n",
        "# Load the labels for a record.\n",
        "def load_labels(record):\n",
        "    header = load_header(record)\n",
        "    labels = get_labels_from_header(header)\n",
        "    return labels\n",
        "\n",
        "# Save the header for a record.\n",
        "def save_header(record, header):\n",
        "    header_file = get_header_file(record)\n",
        "    save_text(header_file, header)\n",
        "\n",
        "# Save the signals for a record.\n",
        "def save_signals(record, signal, comments=list()):\n",
        "    header = load_header(record)\n",
        "    path, record = os.path.split(record)\n",
        "    sampling_frequency = get_sampling_frequency(header)\n",
        "    signal_formats = get_signal_formats(header)\n",
        "    adc_gains = get_adc_gains(header)\n",
        "    baselines = get_baselines(header)\n",
        "    signal_units = get_signal_units(header)\n",
        "    signal_names = get_signal_names(header)\n",
        "    comments = [comment.replace('#', '').strip() for comment in comments]\n",
        "\n",
        "    wfdb.wrsamp(record, fs=sampling_frequency, units=signal_units, sig_name=signal_names, \\\n",
        "                p_signal=signal, fmt=signal_formats, adc_gain=adc_gains, baseline=baselines, comments=comments,\n",
        "                write_dir=path)\n",
        "\n",
        "# Save the labels for a record.\n",
        "def save_labels(record, labels):\n",
        "    header_file = get_header_file(record)\n",
        "    header = load_text(header_file)\n",
        "    header += substring_labels + ' ' + ', '.join(labels) + '\\n'\n",
        "    save_text(header_file, header)\n",
        "    return header\n",
        "\n",
        "### Helper Challenge functions\n",
        "\n",
        "# Load a text file as a string.\n",
        "def load_text(filename):\n",
        "    with open(filename, 'r') as f:\n",
        "        string = f.read()\n",
        "    return string\n",
        "\n",
        "# Save a string as a text file.\n",
        "def save_text(filename, string):\n",
        "    with open(filename, 'w') as f:\n",
        "        f.write(string)\n",
        "\n",
        "# Get a variable from a string.\n",
        "def get_variable(string, variable_name):\n",
        "    variable = ''\n",
        "    has_variable = False\n",
        "    for l in string.split('\\n'):\n",
        "        if l.startswith(variable_name):\n",
        "            variable = l[len(variable_name):].strip()\n",
        "            has_variable = True\n",
        "    return variable, has_variable\n",
        "\n",
        "# Get variables from a string.\n",
        "def get_variables(string, variable_name, sep=','):\n",
        "    variables = list()\n",
        "    has_variable = False\n",
        "    for l in string.split('\\n'):\n",
        "        if l.startswith(variable_name):\n",
        "            variables += [variable.strip() for variable in l[len(variable_name):].strip().split(sep)]\n",
        "            has_variable = True\n",
        "    return variables, has_variable\n",
        "\n",
        "# Get the signal files from a header or a similar string.\n",
        "def get_signal_files_from_header(string):\n",
        "    signal_files = list()\n",
        "    for i, l in enumerate(string.split('\\n')):\n",
        "        arrs = [arr.strip() for arr in l.split(' ')]\n",
        "        if i==0 and not l.startswith('#'):\n",
        "            num_channels = int(arrs[1])\n",
        "        elif i<=num_channels and not l.startswith('#'):\n",
        "            signal_file = arrs[0]\n",
        "            if signal_file not in signal_files:\n",
        "                signal_files.append(signal_file)\n",
        "        else:\n",
        "            break\n",
        "    return signal_files\n",
        "\n",
        "# Get the image files from a header or a similar string.\n",
        "def get_image_files_from_header(string):\n",
        "    images, has_image = get_variables(string, substring_images)\n",
        "    if not has_image:\n",
        "        raise Exception('No images available: did you forget to generate or include the images?')\n",
        "    return images\n",
        "\n",
        "# Get the labels from a header or a similar string.\n",
        "def get_labels_from_header(string):\n",
        "    labels, has_labels = get_variables(string, substring_labels)\n",
        "    if not has_labels:\n",
        "        raise Exception('No labels available: are you trying to load the labels from the held-out data, or did you forget to prepare the data to include the labels?')\n",
        "    return labels\n",
        "\n",
        "# Get the header file for a record.\n",
        "def get_header_file(record):\n",
        "    if not record.endswith('.hea'):\n",
        "        header_file = record + '.hea'\n",
        "    else:\n",
        "        header_file = record\n",
        "    return header_file\n",
        "\n",
        "# Get the signal files for a record.\n",
        "def get_signal_files(record):\n",
        "    header_file = get_header_file(record)\n",
        "    header = load_text(header_file)\n",
        "    signal_files = get_signal_files_from_header(header)\n",
        "    return signal_files\n",
        "\n",
        "# Get the image files for a record.\n",
        "def get_image_files(record):\n",
        "    header_file = get_header_file(record)\n",
        "    header = load_text(header_file)\n",
        "    image_files = get_image_files_from_header(header)\n",
        "    return image_files\n",
        "\n",
        "### WFDB functions\n",
        "\n",
        "# Get the record name from a header file.\n",
        "def get_record_name(string):\n",
        "    value = string.split('\\n')[0].split(' ')[0].split('/')[0].strip()\n",
        "    return value\n",
        "\n",
        "# Get the number of signals from a header file.\n",
        "def get_num_signals(string):\n",
        "    value = string.split('\\n')[0].split(' ')[1].strip()\n",
        "    if is_integer(value):\n",
        "        value = int(value)\n",
        "    else:\n",
        "        value = None\n",
        "    return value\n",
        "\n",
        "# Get the sampling frequency from a header file.\n",
        "def get_sampling_frequency(string):\n",
        "    value = string.split('\\n')[0].split(' ')[2].split('/')[0].strip()\n",
        "    if is_number(value):\n",
        "        value = float(value)\n",
        "    else:\n",
        "        value = None\n",
        "    return value\n",
        "\n",
        "# Get the number of samples from a header file.\n",
        "def get_num_samples(string):\n",
        "    value = string.split('\\n')[0].split(' ')[3].strip()\n",
        "    if is_integer(value):\n",
        "        value = int(value)\n",
        "    else:\n",
        "        value = None\n",
        "    return value\n",
        "\n",
        "# Get the signal formats from a header file.\n",
        "def get_signal_formats(string):\n",
        "    num_signals = get_num_signals(string)\n",
        "    values = list()\n",
        "    for i, l in enumerate(string.split('\\n')):\n",
        "        if 1 <= i <= num_signals:\n",
        "            field = l.split(' ')[1]\n",
        "            if 'x' in field:\n",
        "                field = field.split('x')[0]\n",
        "            if ':' in field:\n",
        "                field = field.split(':')[0]\n",
        "            if '+' in field:\n",
        "                field = field.split('+')[0]\n",
        "            value = field\n",
        "            values.append(value)\n",
        "    return values\n",
        "\n",
        "# Get the ADC gains from a header file.\n",
        "def get_adc_gains(string):\n",
        "    num_signals = get_num_signals(string)\n",
        "    values = list()\n",
        "    for i, l in enumerate(string.split('\\n')):\n",
        "        if 1 <= i <= num_signals:\n",
        "            field = l.split(' ')[2]\n",
        "            if '/' in field:\n",
        "                field = field.split('/')[0]\n",
        "            if '(' in field and ')' in field:\n",
        "                field = field.split('(')[0]\n",
        "            value = float(field)\n",
        "            values.append(value)\n",
        "    return values\n",
        "\n",
        "# Get the baselines from a header file.\n",
        "def get_baselines(string):\n",
        "    num_signals = get_num_signals(string)\n",
        "    values = list()\n",
        "    for i, l in enumerate(string.split('\\n')):\n",
        "        if 1 <= i <= num_signals:\n",
        "            field = l.split(' ')[2]\n",
        "            if '/' in field:\n",
        "                field = field.split('/')[0]\n",
        "            if '(' in field and ')' in field:\n",
        "                field = field.split('(')[1].split(')')[0]\n",
        "            else:\n",
        "                field = get_adc_zeros(string)[i-1]\n",
        "            value = int(field)\n",
        "            values.append(value)\n",
        "    return values\n",
        "\n",
        "# Get the signal units from a header file.\n",
        "def get_signal_units(string):\n",
        "    num_signals = get_num_signals(string)\n",
        "    values = list()\n",
        "    for i, l in enumerate(string.split('\\n')):\n",
        "        if 1 <= i <= num_signals:\n",
        "            field = l.split(' ')[2]\n",
        "            if '/' in field:\n",
        "                value = field.split('/')[1]\n",
        "            else:\n",
        "                value = 'mV'\n",
        "            values.append(value)\n",
        "    return values\n",
        "\n",
        "# Get the ADC resolutions from a header file.\n",
        "def get_adc_resolutions(string):\n",
        "    num_signals = get_num_signals(string)\n",
        "    values = list()\n",
        "    for i, l in enumerate(string.split('\\n')):\n",
        "        if 1 <= i <= num_signals:\n",
        "            field = l.split(' ')[3]\n",
        "            value = int(field)\n",
        "            values.append(value)\n",
        "    return values\n",
        "\n",
        "# Get the ADC zeros from a header file.\n",
        "def get_adc_zeros(string):\n",
        "    num_signals = get_num_signals(string)\n",
        "    values = list()\n",
        "    for i, l in enumerate(string.split('\\n')):\n",
        "        if 1 <= i <= num_signals:\n",
        "            field = l.split(' ')[4]\n",
        "            value = int(field)\n",
        "            values.append(value)\n",
        "    return values\n",
        "\n",
        "# Get the initial values of a signal from a header file.\n",
        "def get_initial_values(string):\n",
        "    num_signals = get_num_signals(string)\n",
        "    values = list()\n",
        "    for i, l in enumerate(string.split('\\n')):\n",
        "        if 1 <= i <= num_signals:\n",
        "            field = l.split(' ')[5]\n",
        "            value = int(field)\n",
        "            values.append(value)\n",
        "    return values\n",
        "\n",
        "# Get the checksums of a signal from a header file.\n",
        "def get_checksums(string):\n",
        "    num_signals = get_num_signals(string)\n",
        "    values = list()\n",
        "    for i, l in enumerate(string.split('\\n')):\n",
        "        if 1 <= i <= num_signals:\n",
        "            field = l.split(' ')[6]\n",
        "            value = int(field)\n",
        "            values.append(value)\n",
        "    return values\n",
        "\n",
        "# Get the block sizes of a signal from a header file.\n",
        "def get_block_sizes(string):\n",
        "    num_signals = get_num_signals(string)\n",
        "    values = list()\n",
        "    for i, l in enumerate(string.split('\\n')):\n",
        "        if 1 <= i <= num_signals:\n",
        "            field = l.split(' ')[7]\n",
        "            value = int(field)\n",
        "            values.append(value)\n",
        "    return values\n",
        "\n",
        "# Get the signal names from a header file.\n",
        "def get_signal_names(string):\n",
        "    num_signals = get_num_signals(string)\n",
        "    values = list()\n",
        "    for i, l in enumerate(string.split('\\n')):\n",
        "        if 1 <= i <= num_signals:\n",
        "            value = l.split(' ')[8]\n",
        "            values.append(value)\n",
        "    return values\n",
        "\n",
        "### Evaluation functions\n",
        "\n",
        "# Construct the binary one-vs-rest confusion matrices, where the columns are the expert labels and the rows are the classifier\n",
        "# for the given classes.\n",
        "def compute_one_vs_rest_confusion_matrix(labels, outputs, classes):\n",
        "    assert np.shape(labels) == np.shape(outputs)\n",
        "\n",
        "    num_instances = len(labels)\n",
        "    num_classes = len(classes)\n",
        "\n",
        "    A = np.zeros((num_classes, 2, 2))\n",
        "    for i in range(num_instances):\n",
        "        for j in range(num_classes):\n",
        "            if labels[i, j] == 1 and outputs[i, j] == 1: # TP\n",
        "                A[j, 0, 0] += 1\n",
        "            elif labels[i, j] == 0 and outputs[i, j] == 1: # FP\n",
        "                A[j, 0, 1] += 1\n",
        "            elif labels[i, j] == 1 and outputs[i, j] == 0: # FN\n",
        "                A[j, 1, 0] += 1\n",
        "            elif labels[i, j] == 0 and outputs[i, j] == 0: # TN\n",
        "                A[j, 1, 1] += 1\n",
        "\n",
        "    return A\n",
        "\n",
        "# Compute macro F-measure.\n",
        "def compute_f_measure(labels, outputs):\n",
        "    # Compute confusion matrix.\n",
        "    classes = sorted(set.union(*map(set, labels)))\n",
        "    labels = compute_one_hot_encoding(labels, classes)\n",
        "    outputs = compute_one_hot_encoding(outputs, classes)\n",
        "    A = compute_one_vs_rest_confusion_matrix(labels, outputs, classes)\n",
        "\n",
        "    num_classes = len(classes)\n",
        "    per_class_f_measure = np.zeros(num_classes)\n",
        "    for k in range(num_classes):\n",
        "        tp, fp, fn, tn = A[k, 0, 0], A[k, 0, 1], A[k, 1, 0], A[k, 1, 1]\n",
        "        if 2 * tp + fp + fn > 0:\n",
        "            per_class_f_measure[k] = float(2 * tp) / float(2 * tp + fp + fn)\n",
        "        else:\n",
        "            per_class_f_measure[k] = float('nan')\n",
        "\n",
        "    if np.any(np.isfinite(per_class_f_measure)):\n",
        "        macro_f_measure = np.nanmean(per_class_f_measure)\n",
        "    else:\n",
        "        macro_f_measure = float('nan')\n",
        "\n",
        "    return macro_f_measure, per_class_f_measure, classes\n",
        "\n",
        "# Reorder channels in signal.\n",
        "def reorder_signal(input_signal, input_channels, output_channels):\n",
        "    # Do not allow repeated channels with potentially different values in a signal.\n",
        "    assert(len(set(input_channels)) == len(input_channels))\n",
        "    assert(len(set(output_channels)) == len(output_channels))\n",
        "\n",
        "    if input_channels == output_channels:\n",
        "        output_signal = input_signal\n",
        "    else:\n",
        "        input_channels = [channel.strip().casefold() for channel in input_channels]\n",
        "        output_channels = [channel.strip().casefold() for channel in output_channels]\n",
        "\n",
        "        input_signal = np.asarray(input_signal)\n",
        "        num_samples = np.shape(input_signal)[0]\n",
        "        num_channels = len(output_channels)\n",
        "        data_type = input_signal.dtype\n",
        "        output_signal = np.zeros((num_samples, num_channels), dtype=data_type)\n",
        "\n",
        "        for i, output_channel in enumerate(output_channels):\n",
        "            for j, input_channel in enumerate(input_channels):\n",
        "                if input_channel == output_channel:\n",
        "                    output_signal[:, i] = input_signal[:, j]\n",
        "\n",
        "    return output_signal\n",
        "\n",
        "# Pad or truncate signal.\n",
        "def trim_signal(input_signal, num_samples_trimmed):\n",
        "    input_signal = np.asarray(input_signal)\n",
        "    num_samples, num_channels = np.shape(input_signal)\n",
        "    data_type = input_signal.dtype\n",
        "\n",
        "    if num_samples == num_samples_trimmed:\n",
        "        output_signal = input_signal\n",
        "    else:\n",
        "        output_signal = np.zeros((num_samples_trimmed, num_channels), dtype=data_type)\n",
        "        if num_samples < num_samples_trimmed: # Zero-pad the signals.\n",
        "            output_signal[:num_samples, :] = input_signal\n",
        "        else: # Truncate the signals.\n",
        "            output_signal = input_signal[:num_samples_trimmed, :]\n",
        "\n",
        "    return output_signal\n",
        "\n",
        "# Compute SNR.\n",
        "def compute_snr(label_signal, output_signal):\n",
        "    label_signal = np.asarray(label_signal)\n",
        "    output_signal = np.asarray(output_signal)\n",
        "\n",
        "    assert(label_signal.ndim == output_signal.ndim == 1)\n",
        "    assert(np.size(label_signal) == np.size(output_signal))\n",
        "\n",
        "    idx_finite_signal = np.isfinite(label_signal)\n",
        "    label_signal = label_signal[idx_finite_signal]\n",
        "    output_signal = output_signal[idx_finite_signal]\n",
        "\n",
        "    idx_nan_signal = np.isnan(output_signal)\n",
        "    output_signal[idx_nan_signal] = 0\n",
        "\n",
        "    noise_signal = output_signal - label_signal\n",
        "\n",
        "    x = np.sum(label_signal**2)\n",
        "    y = np.sum(noise_signal**2)\n",
        "\n",
        "    if x > 0 and y > 0:\n",
        "        snr = 10 * np.log10(x / y)\n",
        "    elif x > 0 and y == 0:\n",
        "        snr = float('inf')\n",
        "    else:\n",
        "        snr = float('nan')\n",
        "\n",
        "    return snr\n",
        "\n",
        "# Compute the mean signal power to median noise power metric.\n",
        "def compute_snr_median(label_signal, output_signal):\n",
        "    label_signal = np.asarray(label_signal)\n",
        "    output_signal = np.asarray(output_signal)\n",
        "\n",
        "    assert(label_signal.ndim == output_signal.ndim == 1)\n",
        "    assert(np.size(label_signal) == np.size(output_signal))\n",
        "\n",
        "    idx_finite_signal = np.isfinite(label_signal)\n",
        "    label_signal = label_signal[idx_finite_signal]\n",
        "    output_signal = output_signal[idx_finite_signal]\n",
        "\n",
        "    idx_nan_signal = np.isnan(output_signal)\n",
        "    output_signal[idx_nan_signal] = 0\n",
        "\n",
        "    noise_signal = output_signal - label_signal\n",
        "\n",
        "    x = np.mean(label_signal**2)\n",
        "    y = np.median(noise_signal**2)\n",
        "\n",
        "    if y > 0:\n",
        "        snr = 10 * np.log10(x / y)\n",
        "    else:\n",
        "        snr = float('inf')\n",
        "\n",
        "    return snr\n",
        "\n",
        "# Compute a metric inspired by the Kolmogorov-Smirnov test statistic.\n",
        "def compute_ks_metric(label_signal, output_signal):\n",
        "    label_signal = np.asarray(label_signal)\n",
        "    output_signal = np.asarray(output_signal)\n",
        "\n",
        "    assert(label_signal.ndim == output_signal.ndim == 1)\n",
        "    assert(np.size(label_signal) == np.size(output_signal))\n",
        "\n",
        "    idx_finite_signal = np.isfinite(label_signal)\n",
        "    label_signal = label_signal[idx_finite_signal]\n",
        "    output_signal = output_signal[idx_finite_signal]\n",
        "\n",
        "    idx_nan_signal = np.isnan(output_signal)\n",
        "    output_signal[idx_nan_signal] = 0\n",
        "\n",
        "    label_signal_cdf = np.cumsum(np.abs(label_signal))\n",
        "    output_signal_cdf = np.cumsum(np.abs(output_signal))\n",
        "\n",
        "    if label_signal_cdf[-1] > 0:\n",
        "        label_signal_cdf = label_signal_cdf / label_signal_cdf[-1]\n",
        "    if output_signal_cdf[-1] > 0:\n",
        "        output_signal_cdf = output_signal_cdf / output_signal_cdf[-1]\n",
        "\n",
        "    goodness_of_fit = 1.0 - np.max(np.abs(label_signal_cdf - output_signal_cdf))\n",
        "\n",
        "    return goodness_of_fit\n",
        "\n",
        "# Compute the adaptive signed correlation index (ASCI) metric.\n",
        "def compute_asci_metric(label_signal, output_signal, beta=0.05):\n",
        "    label_signal = np.asarray(label_signal)\n",
        "    output_signal = np.asarray(output_signal)\n",
        "\n",
        "    assert(label_signal.ndim == output_signal.ndim == 1)\n",
        "    assert(np.size(label_signal) == np.size(output_signal))\n",
        "\n",
        "    idx_finite_signal = np.isfinite(label_signal)\n",
        "    label_signal = label_signal[idx_finite_signal]\n",
        "    output_signal = output_signal[idx_finite_signal]\n",
        "\n",
        "    idx_nan_signal = np.isnan(output_signal)\n",
        "    output_signal[idx_nan_signal] = 0\n",
        "\n",
        "    if beta <= 0 or beta > 1:\n",
        "        raise ValueError('The beta value should be greater than 0 and less than or equal to 1.')\n",
        "\n",
        "    threshold = beta * np.std(label_signal)\n",
        "\n",
        "    noise_signal = np.abs(label_signal - output_signal)\n",
        "\n",
        "    discrete_noise = np.zeros_like(noise_signal)\n",
        "    discrete_noise[noise_signal <= threshold] = 1\n",
        "    discrete_noise[noise_signal > threshold] = -1\n",
        "\n",
        "    asci = np.mean(discrete_noise)\n",
        "\n",
        "    return asci\n",
        "\n",
        "# Compute a weighted absolute difference metric.\n",
        "def compute_weighted_absolute_difference(label_signal, output_signal, sampling_frequency):\n",
        "    label_signal = np.asarray(label_signal)\n",
        "    output_signal = np.asarray(output_signal)\n",
        "\n",
        "    assert(label_signal.ndim == output_signal.ndim == 1)\n",
        "    assert(np.size(label_signal) == np.size(output_signal))\n",
        "\n",
        "    idx_finite_signal = np.isfinite(label_signal)\n",
        "    label_signal = label_signal[idx_finite_signal]\n",
        "    output_signal = output_signal[idx_finite_signal]\n",
        "\n",
        "    idx_nan_signal = np.isnan(output_signal)\n",
        "    output_signal[idx_nan_signal] = 0\n",
        "\n",
        "    from scipy.signal import filtfilt\n",
        "\n",
        "    m = round(0.1 * sampling_frequency)\n",
        "    w = filtfilt(np.ones(m), m, label_signal, method='gust')\n",
        "    w = 1 - 0.5/np.max(w) * w\n",
        "    n = np.sum(w)\n",
        "\n",
        "    weighted_absolute_difference_metric = np.sum(np.abs(label_signal-output_signal) * w)/n\n",
        "\n",
        "    return weighted_absolute_difference_metric\n",
        "\n",
        "### Other helper functions\n",
        "\n",
        "# Check if a variable is a number or represents a number.\n",
        "def is_number(x):\n",
        "    try:\n",
        "        float(x)\n",
        "        return True\n",
        "    except (ValueError, TypeError):\n",
        "        return False\n",
        "\n",
        "# Check if a variable is an integer or represents an integer.\n",
        "def is_integer(x):\n",
        "    if is_number(x):\n",
        "        return float(x).is_integer()\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "# Check if a variable is a finite number or represents a finite number.\n",
        "def is_finite_number(x):\n",
        "    if is_number(x):\n",
        "        return np.isfinite(float(x))\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "# Check if a variable is a NaN (not a number) or represents a NaN.\n",
        "def is_nan(x):\n",
        "    if is_number(x):\n",
        "        return np.isnan(float(x))\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "# Cast a value to an integer if an integer, a float if a non-integer float, and an unknown value otherwise.\n",
        "def cast_int_float_unknown(x):\n",
        "    if is_integer(x):\n",
        "        x = int(x)\n",
        "    elif is_finite_number(x):\n",
        "        x = float(x)\n",
        "    elif is_number(x):\n",
        "        x = 'Unknown'\n",
        "    else:\n",
        "        raise NotImplementedError(f'Unable to cast {x}.')\n",
        "    return x\n",
        "\n",
        "# Construct the one-hot encoding of data for the given classes.\n",
        "def compute_one_hot_encoding(data, classes):\n",
        "    num_instances = len(data)\n",
        "    num_classes = len(classes)\n",
        "\n",
        "    one_hot_encoding = np.zeros((num_instances, num_classes), dtype=np.bool_)\n",
        "    unencoded_data = list()\n",
        "    for i, x in enumerate(data):\n",
        "        for y in x:\n",
        "            for j, z in enumerate(classes):\n",
        "                if (y == z) or (is_nan(y) and is_nan(z)):\n",
        "                    one_hot_encoding[i, j] = 1\n",
        "\n",
        "    return one_hot_encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading Images"
      ],
      "metadata": {
        "id": "kN3rhFOerKNH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features(record):\n",
        "    images = load_images(record)\n",
        "    return np.array(images[0])"
      ],
      "metadata": {
        "id": "2rY04VZ5rpQV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(data_folder, model_folder, verbose=True):\n",
        "\n",
        "    records = find_records(data_folder)\n",
        "    num_records = len(records)\n",
        "\n",
        "\n",
        "    classification_features = list()\n",
        "    classification_labels = list()\n",
        "\n",
        "    # Iterate over the records.\n",
        "    for i in range(num_records):\n",
        "        if verbose:\n",
        "            width = len(str(num_records))\n",
        "            print(f'- {i+1:>{width}}/{num_records}: {records[i]}...')\n",
        "\n",
        "        record = os.path.join(data_folder, records[i])\n",
        "\n",
        "        # Extract the features from the image; this simple example uses the same features for the digitization and classification\n",
        "        # tasks.\n",
        "        features = extract_features(record)\n",
        "\n",
        "\n",
        "\n",
        "        # Some images may not be labeled...\n",
        "        labels = load_labels(record)\n",
        "\n",
        "        if any(label for label in labels):\n",
        "            classification_features.append(features)\n",
        "            classification_labels.append(labels)\n",
        "\n",
        "    return classification_features, classification_labels\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "SARcG9HGrH5B"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}